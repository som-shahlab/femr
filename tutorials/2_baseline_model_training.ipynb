{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "31268d33-8a17-4b70-8148-37bf031bfcac",
   "metadata": {},
   "source": [
    "# Baseline Model Training with Custom Labeler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bf25c71-ef4e-4382-acac-94d9823aec05",
   "metadata": {},
   "source": [
    "In this notebook, we will show an end-to-end process of using piton to apply custom labeling function and generate features, and train a simple baseline models such as logistic regression and xgboost. The example dataset used here is the STARR OMOP dataset extracted in the previous notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e3d4611a-a1f8-4e23-972b-6b22b81c94ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a2727de-a745-4591-8357-2ca5cadb1136",
   "metadata": {},
   "source": [
    "Please follow the installation guide for piton on readme. You may need to install few other packages such as sklearn and xgboost. Use `pip install <package>`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "06867df0-4a56-4cb5-8c92-315e3c6fa5e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import os\n",
    "from typing import List, Tuple\n",
    "\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "\n",
    "import piton\n",
    "import piton.datasets\n",
    "from piton.labelers.core import Label, LabeledPatients, TimeHorizon\n",
    "from piton.labelers.omop_labeling_functions import CodeLF, MortalityLF, IsMaleLF, DiabetesLF\n",
    "from piton.featurizers.core import Featurizer, FeaturizerList\n",
    "from piton.featurizers.featurizers import AgeFeaturizer, CountFeaturizer\n",
    "from piton.extension import datasets as extension_datasets\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from tqdm import tqdm\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c6967909-bfba-41c1-aa38-f69bad843179",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Please update this path with your extract of piton as noted in previous notebook. \n",
    "PATH_TO_PITON_DB = '/local-scratch/nigam/projects/clmbr_text_assets/data/piton_database_1_perct/'\n",
    "\n",
    "# Patient database\n",
    "data = piton.datasets.PatientDatabase(PATH_TO_PITON_DB)\n",
    "\n",
    "# Ontology \n",
    "ontology = data.get_ontology()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8875dc2d-1c96-445c-be25-c929c85723ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on PatientDatabase in module piton.extension.datasets object:\n",
      "\n",
      "class PatientDatabase(collections.abc.Sequence, pybind11_builtins.pybind11_object)\n",
      " |  Method resolution order:\n",
      " |      PatientDatabase\n",
      " |      collections.abc.Sequence\n",
      " |      collections.abc.Reversible\n",
      " |      collections.abc.Collection\n",
      " |      collections.abc.Sized\n",
      " |      collections.abc.Iterable\n",
      " |      collections.abc.Container\n",
      " |      pybind11_builtins.pybind11_object\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __getitem__(...)\n",
      " |      __getitem__(self: object, arg0: int) -> object\n",
      " |  \n",
      " |  __init__(...)\n",
      " |      __init__(self: piton.extension.datasets.PatientDatabase, filename: str, read_all: bool = False) -> None\n",
      " |  \n",
      " |  __len__(...)\n",
      " |      __len__(self: piton.extension.datasets.PatientDatabase) -> int\n",
      " |  \n",
      " |  close(...)\n",
      " |      close(self: piton.extension.datasets.PatientDatabase) -> None\n",
      " |  \n",
      " |  get_code_count(...)\n",
      " |      get_code_count(self: piton.extension.datasets.PatientDatabase, arg0: int) -> int\n",
      " |  \n",
      " |  get_code_dictionary(...)\n",
      " |      get_code_dictionary(self: piton.extension.datasets.PatientDatabase) -> Dictionary\n",
      " |  \n",
      " |  get_ontology(...)\n",
      " |      get_ontology(self: piton.extension.datasets.PatientDatabase) -> Ontology\n",
      " |  \n",
      " |  get_original_patient_id(...)\n",
      " |      get_original_patient_id(self: piton.extension.datasets.PatientDatabase, arg0: int) -> int\n",
      " |  \n",
      " |  get_patient_id_from_original(...)\n",
      " |      get_patient_id_from_original(self: piton.extension.datasets.PatientDatabase, arg0: int) -> Optional[int]\n",
      " |  \n",
      " |  get_text_count(...)\n",
      " |      get_text_count(self: piton.extension.datasets.PatientDatabase, arg0: str) -> int\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from collections.abc.Sequence:\n",
      " |  \n",
      " |  __contains__(self, value)\n",
      " |  \n",
      " |  __iter__(self)\n",
      " |  \n",
      " |  __reversed__(self)\n",
      " |  \n",
      " |  count(self, value)\n",
      " |      S.count(value) -> integer -- return number of occurrences of value\n",
      " |  \n",
      " |  index(self, value, start=0, stop=None)\n",
      " |      S.index(value, [start, [stop]]) -> integer -- return first index of value.\n",
      " |      Raises ValueError if the value is not present.\n",
      " |      \n",
      " |      Supporting start and stop arguments is optional, but\n",
      " |      recommended.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes inherited from collections.abc.Sequence:\n",
      " |  \n",
      " |  __abstractmethods__ = frozenset({'__getitem__', '__len__'})\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from collections.abc.Reversible:\n",
      " |  \n",
      " |  __subclasshook__(C) from pybind11_builtins.pybind11_type\n",
      " |      Abstract classes can override this to customize issubclass().\n",
      " |      \n",
      " |      This is invoked early on by abc.ABCMeta.__subclasscheck__().\n",
      " |      It should return True, False or NotImplemented.  If it returns\n",
      " |      NotImplemented, the normal algorithm is used.  Otherwise, it\n",
      " |      overrides the normal algorithm (and the outcome is cached).\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from collections.abc.Iterable:\n",
      " |  \n",
      " |  __class_getitem__ = GenericAlias(...) from pybind11_builtins.pybind11_type\n",
      " |      Represent a PEP 585 generic type\n",
      " |      \n",
      " |      E.g. for t = list[int], t.__origin__ is list and t.__args__ is (int,).\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Static methods inherited from pybind11_builtins.pybind11_object:\n",
      " |  \n",
      " |  __new__(*args, **kwargs) from pybind11_builtins.pybind11_type\n",
      " |      Create and return a new object.  See help(type) for accurate signature.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a45f516c-059a-4962-b63f-fa7e7b5c93bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on Ontology in module piton.extension.datasets object:\n",
      "\n",
      "class Ontology(pybind11_builtins.pybind11_object)\n",
      " |  Method resolution order:\n",
      " |      Ontology\n",
      " |      pybind11_builtins.pybind11_object\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, /, *args, **kwargs)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  get_all_parents(...)\n",
      " |      get_all_parents(self: piton.extension.datasets.Ontology, arg0: int) -> piton.extension.IntSpan\n",
      " |  \n",
      " |  get_children(...)\n",
      " |      get_children(self: piton.extension.datasets.Ontology, arg0: int) -> piton.extension.IntSpan\n",
      " |  \n",
      " |  get_dictionary(...)\n",
      " |      get_dictionary(self: piton.extension.datasets.Ontology) -> Dictionary\n",
      " |  \n",
      " |  get_parents(...)\n",
      " |      get_parents(self: piton.extension.datasets.Ontology, arg0: int) -> piton.extension.IntSpan\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Static methods inherited from pybind11_builtins.pybind11_object:\n",
      " |  \n",
      " |  __new__(*args, **kwargs) from pybind11_builtins.pybind11_type\n",
      " |      Create and return a new object.  See help(type) for accurate signature.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(ontology)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a9134919-1283-4900-be20-cf481035f805",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For sake for running the demo fast, lets only use 100 patients\n",
    "patients = [data[i] for i in range(0, 10)]\n",
    "patients = data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c627088-9f51-43c5-be6e-f579e325b034",
   "metadata": {},
   "source": [
    "#### First, let use use labelers and featurizers provided with Piton. The task is to predict mortality in next 1 year. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "31199e63-393b-40a3-b809-d36704eb90e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define time horizon for labeling purpose based on your use case. \n",
    "# Note: Some labeling function may not take any time_horizon\n",
    "\n",
    "time_horizon = TimeHorizon(\n",
    "        datetime.timedelta(days=0), datetime.timedelta(days=365)\n",
    "    )\n",
    "\n",
    "# Define the mortality labeling function. \n",
    "# labeler = MortalityLF(ontology, time_horizon)\n",
    "labeler = DiabetesLF(ontology, time_horizon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3b79076b-c5b3-4538-96cf-69e81837a3d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_patients = labeler.apply(patients, PATH_TO_PITON_DB, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "bb276483-009a-4822-ba43-6710ba11e869",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def save_to_file(object_to_save, path_to_file: str):\n",
    "#     \"\"\"Save object to Pickle file.\"\"\"\n",
    "#     os.makedirs(os.path.dirname(path_to_file), exist_ok=True)\n",
    "#     with open(path_to_file, \"wb\") as fd:\n",
    "#         pickle.dump(object_to_save, fd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b64d2b9d-5334-4363-b107-fd973d907a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# save_to_file(labeler, \"./test_labeler.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d3ae2447-69f9-415c-8563-c17846eee56f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets use both age and count featurizer \n",
    "age = AgeFeaturizer()\n",
    "count = CountFeaturizer(rollup=True)\n",
    "featurizer_age_count = FeaturizerList([age, count])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e04c4a01-9d28-4e81-9baa-49b40b632886",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_to_file(featurizer_age_count, \"./featurizer_age_count_1.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d8c8b3b2-4d40-4689-83b7-1022d029cbb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 3166.23it/s]\n"
     ]
    }
   ],
   "source": [
    "# Preprocessing the featurizers, which includes processes such as normalizing age. \n",
    "featurizer_age_count.preprocess_featurizers(patients, labeled_patients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "904ac97e-9013-40b2-9cc3-e87b270c2ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_matrix, labels, _, _ = featurizer_age_count.featurize(patients, labeled_patients, num_threads=5, database_path=PATH_TO_PITON_DB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7de83a25-15a4-44c4-9aa2-8286a0f43b9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b631aa48-11e5-47e8-a438-50b3298e1a65",
   "metadata": {},
   "source": [
    "#### Training baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "91557a95-b8fe-4244-a25e-5eb5f75022a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(full_matrix, labels, train_size = 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "cf576225-82ec-4697-bec1-7acad3f5b85a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5472, 31559)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "c3cea876-de2b-43aa-a4be-a55f6ef42722",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1369, 31559)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "8849f8a2-c2dc-484a-a395-d4a1c8e40897",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "174.0"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "4456c07c-da01-4cf3-a068-a593767f0329",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9307122589332948\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rthapa84/.conda/envs/env_piton/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regresion\n",
    "model = LogisticRegression().fit(X_train, y_train)\n",
    "y_pred_proba = model.predict_proba(X_test)[::,1]\n",
    "auc = metrics.roc_auc_score(y_test, y_pred_proba)\n",
    "print(auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "05086f52-a07e-404d-a190-4d91c213d560",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9870076468042129\n"
     ]
    }
   ],
   "source": [
    "# XGBoost\n",
    "params = {\n",
    "    \"n_estimators\": 50, \n",
    "    \"max_depth\": 2\n",
    "}\n",
    "\n",
    "model = xgb.XGBClassifier(**params)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred_proba = model.predict_proba(X_test)[::,1]\n",
    "auc = metrics.roc_auc_score(y_test, y_pred_proba)\n",
    "print(auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bffe9088-459a-441b-8214-494d4d5659fe",
   "metadata": {},
   "source": [
    "## Now, let us make a custom labeler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "1850c8e9-a9bf-4f2d-aaf3-b71a5a19dcad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Piton Code:  1243\n",
      "Count in dataset:  4009\n",
      "Prevalence:  11.87\n"
     ]
    }
   ],
   "source": [
    "DIABETES_CODE = \"SNOMED/44054006\"\n",
    "\n",
    "piton_code = data.get_code_dictionary().index(DIABETES_CODE)\n",
    "\n",
    "print(\"Piton Code: \", piton_code)\n",
    "print(\"Count in dataset: \", data.get_code_count(piton_code))\n",
    "print(\"Prevalence: \", round(data.get_code_count(piton_code)/len(data)*100, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72afc0b4-91bb-4456-ab51-5ed831a4a68f",
   "metadata": {},
   "source": [
    "An example of how to make a custom labeler. This labeler is also included in `labelers.omop_labeling_functions` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "459441c9-fba6-4016-ac30-2c3660d6d541",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiabetesLF(CodeLF):\n",
    "    \"\"\"Apply a label for whether or not a patient has diabetes within the `time_horizon`.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self, ontology: extension_datasets.Ontology, time_horizon: TimeHorizon\n",
    "    ):\n",
    "        \"\"\"Create a Diabetes labeler.\n",
    "\n",
    "        Args:\n",
    "            ontology (extension_datasets.Ontology): Maps code IDs to concept names\n",
    "            time_horizon (TimeHorizon): An interval of time. If the event occurs during this time horizon, then\n",
    "                the label is TRUE. Otherwise, FALSE.\n",
    "\n",
    "        Raises:\n",
    "            ValueError: Raised if there are multiple unique codes that map to the death code\n",
    "        \"\"\"\n",
    "        DIABETES_CODE = \"SNOMED/44054006\"\n",
    "\n",
    "        diabetes_codes: Set[Tuple[str, int]] = set()\n",
    "        for code, code_str in enumerate(ontology.get_dictionary()):\n",
    "            code_str = bytes(code_str).decode('utf-8')\n",
    "            if code_str == DIABETES_CODE:\n",
    "                diabetes_codes.add((code_str, code))\n",
    "\n",
    "        if len(diabetes_codes) != 1:\n",
    "            raise ValueError(\n",
    "                f\"Could not find exactly one death code -- instead found {len(diabetes_codes)} codes: {str(diabetes_codes)}\"\n",
    "            )\n",
    "        else:\n",
    "            diabetes_code: int = list(diabetes_codes)[0][1]\n",
    "            super().__init__(code=diabetes_code, time_horizon=time_horizon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b123047d-5aa6-4873-9f46-44d983824d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_horizon = TimeHorizon(\n",
    "        datetime.timedelta(days=0), datetime.timedelta(days=90)\n",
    "    )\n",
    "\n",
    "labeler = DiabetesLF(ontology, time_horizon)\n",
    "\n",
    "age = AgeFeaturizer()\n",
    "count = CountFeaturizer(ontology=ontology, rollup=True)\n",
    "featurizer_age_count = FeaturizerList([age, count])\n",
    "\n",
    "featurizer_age_count.preprocess_featurizers(patients, labeler)\n",
    "full_matrix, labels, _, _ = featurizer_age_count.featurize(patients, labeler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "1fdf234c-7553-42d3-83bc-0e25f07592b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(full_matrix, labels, train_size = 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ce97687f-16be-4622-9c1f-0693b4f737b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rthapa84/.conda/envs/env_piton/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.99937700249199"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "model = LogisticRegression().fit(X_train, y_train)\n",
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "9c46dfd4-435a-4e8e-908b-37452803f2c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9999110003559986"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# XGBoost\n",
    "params = {\n",
    "    \"n_estimators\": 50, \n",
    "    \"max_depth\": 2\n",
    "}\n",
    "\n",
    "model = xgb.XGBClassifier(**params)\n",
    "model.fit(X_train, y_train)\n",
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8af2fe98-7c04-42d7-8254-d1bd99615f66",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
