{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How FEMR ETLs Work\n",
    "\n",
    "In this notebook, we go through a toy example of writing a custom ETL for FEMR on a custom dataset. \n",
    "\n",
    "We will define a set of patients who have a unique set of associated clinical events, and then initialize a FEMR dataset with this data. \n",
    "\n",
    "Before going through this tutorial, please make sure you've installed **FEMR** as detailed in the [README.md](https://github.com/som-shahlab/femr)\n",
    "\n",
    "#### Learning Goals.\n",
    "1. Initialize a FEMR dataset from scratch with custom data.\n",
    "2. Understand the three steps of the FEMR data pipeline: `EventCollection` => `PatientCollection` => `PatientDatabase`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import os\n",
    "import contextlib\n",
    "import femr\n",
    "import femr.datasets\n",
    "import io\n",
    "import zstandard\n",
    "import csv\n",
    "import functools\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Overview of **FEMR**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **FEMR** workflow of creating patient timelines from an EHR dataset is as follows:\n",
    "\n",
    "1. Extract clinical events from the source EHR database. This could be OMOP-CDM, MIMIC-III, eICU, etc.\n",
    "    * This code is specific to the source EHR database, and is not covered in this tutorial.\n",
    "    * We have already written extractors for some popular EHR databases in the `src/femr/extractors` folder.\n",
    "2. Write these extracted events to disk as an `EventCollection`. \n",
    "    * In an abstract sense, an `EventCollection` is simply an unordered list of `(Patient ID, RawEvent)` tuples. \n",
    "    * Internally, **FEMR** will shard these tuples across a set of files on disk that will be stored in a single folder, but you don't need to worry about that.\n",
    "3. Transform the `EventCollection` into a `PatientCollection`. \n",
    "    * In an abstract sense, a `PatientCollection` is a **sorted** list of `(Patient ID, Event)` tuples, where the sorting is done first by `Patient ID`, second by the `start` time of each `Event`. \n",
    "    * Internally, **FEMR** will shard these consecutively arranged tuples across a set of files on disk that will be stored in a single folder, but you don't need to worry about that.\n",
    "4. Apply transformations to your patient timelines (e.g. move coding assignments to the end of their visits, move all events before a patient's birthdate to after their birthdate, etc.) that you want to your `PatientCollection` to generate a new `PatientCollection`.\n",
    "5. Index and save your `PatientCollection` to disk as a `PatientDatabase`.\n",
    "    * In an abstract sense, a `PatientDatabase` lets you quickly retrieve all the events for a given patient ID. \n",
    "    * Internally, **FEMR** will create another set of indexes and files on disk that will be stored in a single folder, but you don't need to worry about that.\n",
    "\n",
    "Note that everything is done on disk (i.e. not in memory), so you can work with arbitrarily large datasets. \n",
    "\n",
    "However, this means that you must specify the location of the folders where you want to store your `EventCollection`, `PatientCollection`, and `PatientDatabase` on disk."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Define our dataset with `RawPatient` and `RawEvent` objects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RawPatients\n",
    "\n",
    "FEMR represents every raw input patients with the `RawPatient` class. \n",
    "\n",
    "A `RawPatient` object contains the following two attributes:\n",
    "\n",
    "* `patient_id` (str): a unique identifier for the patient\n",
    "* `events` (list): a list of `RawEvent` objects associated with that patient\n",
    "\n",
    "The definition of the `RawPatient` class can be [found here](https://github.com/som-shahlab/femr/blob/main/src/femr/datasets/types.py#L9)\n",
    "\n",
    "#### RawEvents\n",
    "\n",
    "FEMR represents raw input clinical events with the `RawEvent` object.\n",
    "\n",
    "An `RawEvent` object can contain any number of arbitrary attributes, but it must have at least the following two attributes:\n",
    "\n",
    "* `start` (datetime.datetime): the start time of the event\n",
    "* `concept_id` (int): the concept id for that event\n",
    "\n",
    "The definition of the `RawEvent` class can be [found here](https://github.com/som-shahlab/femr/blob/main/src/femr/datasets/types.py#L20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, we'll create some events for some fictional patients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "events = [\n",
    "    # This event contains the bare minimum attributes -- start and code.\n",
    "    femr.datasets.RawEvent(\n",
    "        start=datetime.datetime(2010, 1, 5),\n",
    "        concept_id=2,\n",
    "    ),\n",
    "    # This event contains a couple custom attributes -- value and source_table.\n",
    "    femr.datasets.RawEvent(\n",
    "        start=datetime.datetime(2010, 1, 3, hour=10, minute=45),\n",
    "        concept_id=2,\n",
    "        value=\"test_value\",\n",
    "        source_table=None,\n",
    "    ),\n",
    "    # This event contains even more attributes.\n",
    "    femr.datasets.RawEvent(\n",
    "        start=datetime.datetime(2010, 1, 3, hour=10, minute=30),\n",
    "        concept_id=0,\n",
    "        value=34.0,\n",
    "        source_table='visit',\n",
    "        extra_attr=True,\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our events, let's create a couple fictional patients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[RawEvent(start=2010-01-05 00:00:00, concept_id=2),\n",
       " RawEvent(start=2010-01-03 10:45:00, concept_id=2, value=test_value)]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patients = [\n",
    "    # Let's assign each patient a subset of our events for example purposes.\n",
    "    femr.datasets.RawPatient(patient_id=0, events=events[:2]),\n",
    "    femr.datasets.RawPatient(patient_id=1, events=events[1:]),\n",
    "    femr.datasets.RawPatient(patient_id=10, events=events),\n",
    "]\n",
    "\n",
    "# Lets print out the events of one patient to see what they look like.\n",
    "# Note that attributes associated with `None` (i.e. `source_table` in the \n",
    "# second event) won't be printed out, but they are still tracked internally by femr.\n",
    "patients[0].events"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can access a specific event's attributes as follows. Note that accessing an attribute that wasn't defined on an event will return `None` by default (rather than raise an exception)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patient 0:\n",
      "    Event #0:\n",
      "       Start = 2010-01-05 00:00:00 | Concept_Id = 2 | Value = None | Source Table = None | Extra Attr = None\n",
      "    Event #1:\n",
      "       Start = 2010-01-03 10:45:00 | Concept_Id = 2 | Value = test_value | Source Table = None | Extra Attr = None\n",
      "Patient 1:\n",
      "    Event #0:\n",
      "       Start = 2010-01-03 10:45:00 | Concept_Id = 2 | Value = test_value | Source Table = None | Extra Attr = None\n",
      "    Event #1:\n",
      "       Start = 2010-01-03 10:30:00 | Concept_Id = 0 | Value = 34.0 | Source Table = visit | Extra Attr = True\n",
      "Patient 10:\n",
      "    Event #0:\n",
      "       Start = 2010-01-05 00:00:00 | Concept_Id = 2 | Value = None | Source Table = None | Extra Attr = None\n",
      "    Event #1:\n",
      "       Start = 2010-01-03 10:45:00 | Concept_Id = 2 | Value = test_value | Source Table = None | Extra Attr = None\n",
      "    Event #2:\n",
      "       Start = 2010-01-03 10:30:00 | Concept_Id = 0 | Value = 34.0 | Source Table = visit | Extra Attr = True\n"
     ]
    }
   ],
   "source": [
    "for patient in patients:\n",
    "    print(f\"Patient {patient.patient_id}:\")\n",
    "    for idx, event in enumerate(patient.events):\n",
    "        print(f\"    Event #{idx}:\")\n",
    "        print(f\"       Start = {event.start} | Concept_Id = {event.concept_id} | Value = {event.value} | Source Table = {event.source_table} | Extra Attr = {event.extra_attr}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Create an `EventCollection` from our events"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step in generating a **FEMR** database is to first create an `EventCollection`. \n",
    "\n",
    "You can think of an `EventCollection` as simply an unordered list of all of our events.\n",
    "\n",
    "An `EventCollection` is simply an unordered list of events, where each event is associated with a specific patient ID.\n",
    "\n",
    "Because it is internally represented by **FEMR** as a folder containing multiple files across which events will be sharded, we must specify a **target directory** where **FEMR** can store our `EventCollection`.\n",
    "\n",
    "We can create an `EventCollection` from a list of events as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create directory to store EventCollection\n",
    "target_directory = \"../ignore/dataset_tutorial_target/\"\n",
    "if os.path.exists(target_directory):\n",
    "    shutil.rmtree(target_directory)\n",
    "os.makedirs(target_directory, exist_ok=True)\n",
    "\n",
    "# Create EventCollection\n",
    "event_collection = femr.datasets.EventCollection(\n",
    "    os.path.join(target_directory, \"events\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we'll actually add `RawEvent`s into our `EventCollection`.\n",
    "\n",
    "First, we must call `EventCollection.create_writer()` in order to create a writer object that will be used to write events to the `EventCollection` on disk (remember that everything in **femr** lives on disk). \n",
    "\n",
    "Then, we can call `add_event()` to add each individual event to our `EventCollection`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add events to the EventCollection\n",
    "with contextlib.closing(event_collection.create_writer()) as writer:\n",
    "    # NOTE: We need to use the `create_writer()` handler to create\n",
    "    # a writer object for adding events to the EventCollection\n",
    "    # This will automatically create a new file for these events\n",
    "    for patient in patients:\n",
    "        for event in patient.events:\n",
    "            # Note that these are getting written to disk as part of the EventCollection\n",
    "            writer.add_event(patient_id=patient.patient_id, \n",
    "                             event=event)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to read events from an `EventCollection`, we use the `EventCollection.create_reader()` method to ingest events from disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, RawEvent(start=2010-01-05 00:00:00, concept_id=2))\n",
      "(0, RawEvent(start=2010-01-03 10:45:00, concept_id=2, value=test_value))\n",
      "(1, RawEvent(start=2010-01-03 10:45:00, concept_id=2, value=test_value))\n",
      "(1, RawEvent(start=2010-01-03 10:30:00, concept_id=0, value=34.0, source_table=visit, extra_attr=True))\n",
      "(10, RawEvent(start=2010-01-05 00:00:00, concept_id=2))\n",
      "(10, RawEvent(start=2010-01-03 10:45:00, concept_id=2, value=test_value))\n",
      "(10, RawEvent(start=2010-01-03 10:30:00, concept_id=0, value=34.0, source_table=visit, extra_attr=True))\n"
     ]
    }
   ],
   "source": [
    "# We need to create a reader object as an EventCollection will be natively stored on disk\n",
    "# Note that (Patient ID, Event) tuples can be returned in any order -- femr makes no guarantees\n",
    "with event_collection.reader() as reader:\n",
    "    for event in reader:\n",
    "        print(event)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Create a `PatientCollection` from our `EventCollection`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To recap, an `EventCollection` is simply an unordered list of **(Patient ID, Event)** tuples. \n",
    "\n",
    "Our next step is to sort this unordered list such that all of a patient's events are grouped together, and within each patient, all of their events are sorted chronologically.\n",
    "\n",
    "In other words, we go from this `EventCollection`:\n",
    "\n",
    "1. (Patient 1, Event @ 2020)\n",
    "1. (Patient 2, Event @ 2021)\n",
    "1. (Patient 1, Event @ 2020)\n",
    "1. (Patient 3, Event @ 2020)\n",
    "1. (Patient 1, Event @ 2019)\n",
    "1. (Patient 1, Event @ 2021)\n",
    "1. (Patient 2, Event @ 2019)\n",
    "\n",
    "to this `PatientCollection`:\n",
    "\n",
    "1. (Patient 1, Event @ 2019)\n",
    "1. (Patient 1, Event @ 2020)\n",
    "1. (Patient 1, Event @ 2020)\n",
    "1. (Patient 1, Event @ 2021)\n",
    "1. (Patient 2, Event @ 2019)\n",
    "1. (Patient 2, Event @ 2021)\n",
    "1. (Patient 3, Event @ 2020)\n",
    "\n",
    "To accomplish this, we simply call the `EventCollection.to_patient_collection(path_to_dir)` method. We must provide it with `path_to_dir`, which is the directory where we want to store our `PatientCollection`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "patients = event_collection.to_patient_collection(\n",
    "    os.path.join(target_directory, \"patients\"),\n",
    "    num_threads=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to read events from a `PatientCollection`, we use the `PatientCollection.create_reader()` method to ingest events from disk.\n",
    "\n",
    "Wheras the `EventCollection` returns a single event with each iteration, the `PatientCollection` returns a single **patient** with each iteration. \n",
    "\n",
    "Each patient can contain an arbitrary number of events in its `.events` property. These events are guaranteed to be sorted in chronological order, from least recent to most recent events."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patient: 0\n",
      "\t RawEvent(start=2010-01-03 10:45:00, concept_id=2, value=test_value)\n",
      "\t RawEvent(start=2010-01-05 00:00:00, concept_id=2)\n",
      "Patient: 1\n",
      "\t RawEvent(start=2010-01-03 10:30:00, concept_id=0, value=34.0, source_table=visit, extra_attr=True)\n",
      "\t RawEvent(start=2010-01-03 10:45:00, concept_id=2, value=test_value)\n",
      "Patient: 10\n",
      "\t RawEvent(start=2010-01-03 10:30:00, concept_id=0, value=34.0, source_table=visit, extra_attr=True)\n",
      "\t RawEvent(start=2010-01-03 10:45:00, concept_id=2, value=test_value)\n",
      "\t RawEvent(start=2010-01-05 00:00:00, concept_id=2)\n"
     ]
    }
   ],
   "source": [
    "# We need to create a reader object to read our PatientCollection from disk\n",
    "# Note that a Patient object is returned, and we can access its events in chronological \n",
    "# order by looping through the .events property of the patient\n",
    "with patients.reader() as reader:\n",
    "    for patient in reader:\n",
    "        print('Patient:', patient.patient_id)\n",
    "        for event in patient.events:\n",
    "            print('\\t', event)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Apply transformations to our `PatientCollection`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've ingested our raw EHR data, we will often want to apply transformations to this data in order to make it more useful for our downstream analyses.\n",
    "\n",
    "For example, moving ICD codes to the end of a patient's visit, moving all events before a patient's birthdate to after their birthdate, dropping events after a patient's death is recorded, deduplicating overlapping visits, etc.\n",
    "\n",
    "FEMR follows the \"configuration as code\" mindset by forcing you to explicitly define the transformations you apply to your dataset as a set of composable Python functions.\n",
    "\n",
    "Each transformation should take as input a single `Patient` object and return either a new `Patient` object or `None` (the latter is used to indicate that the patient should be dropped from the dataset)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This transformation function will remove all events from \n",
    "# the input Patientwith that have a value of \"test_value\"\n",
    "def transform_event_value(input: femr.Patient) -> femr.Patient:\n",
    "    return femr.Patient(\n",
    "        patient_id=input.patient_id,\n",
    "        events=[\n",
    "            a\n",
    "            for a in input.events\n",
    "            if a.value != \"test_value\" # Remove test_value for some reason\n",
    "        ],\n",
    "    )\n",
    "\n",
    "# Apply transformation to each Patient in our PatientCollection\n",
    "transformed_patients: femr.datasets.PatientCollection = patients.transform(\n",
    "    os.path.join(target_directory, \"transformed_patients\"),\n",
    "    transform_event_value,\n",
    "    num_threads=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've written our transformed patients to disk, we can read them back in as usual using our `PatientCollection.reader()` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patient: 0\n",
      "\t RawEvent(start=2010-01-05 00:00:00, concept_id=2)\n",
      "Patient: 1\n",
      "\t RawEvent(start=2010-01-03 10:30:00, concept_id=0, value=34.0, source_table=visit, extra_attr=True)\n",
      "Patient: 10\n",
      "\t RawEvent(start=2010-01-03 10:30:00, concept_id=0, value=34.0, source_table=visit, extra_attr=True)\n",
      "\t RawEvent(start=2010-01-05 00:00:00, concept_id=2)\n"
     ]
    }
   ],
   "source": [
    "# Check that our transformation worked -- we shouldn't\n",
    "# see any events with a value of \"test_value\" in our output\n",
    "with transformed_patients.reader() as reader:\n",
    "    for patient in reader:\n",
    "        print('Patient:', patient.patient_id)\n",
    "        for event in patient.events:\n",
    "            print('\\t', event)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Create a `PatientDatabase` from our `PatientCollection`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've loaded, cleaned, and transformed our EHR data, our final step is to save a fast, indexed version of it to disk so that we can quickly iterate over and retrieve patients when we train our machine learning model.\n",
    "\n",
    "FEMR refers to this fast, indexed version of our dataset as a `PatientDatabase`.\n",
    "\n",
    "We can create a `PatientDatabase` as follows:\n",
    "1. Create a `PatientCollection` object (already done)\n",
    "2. Create an `Ontology` folder containing the unique Event codes that appear in our dataset (need to do)\n",
    "3. Create a `PatientDatabase` object from our `PatientCollection` object and `Ontology` (need to do)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will create our `Ontology` by creating two files on disk -- `concept.csv` and `concept_relationship.csv`. We will pass the paths to these files to the `PatientDatabase` constructor.\n",
    "\n",
    "All unique event codes in our dataset must be present in the `concept.csv` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_ontology(path_to_ontology_dir: str, concepts = []):\n",
    "    path_to_concept_file: str = os.path.join(\n",
    "        path_to_ontology_dir, \"concept\", \"concept.csv.zst\"\n",
    "    )\n",
    "    os.makedirs(os.path.dirname(path_to_concept_file), exist_ok=True)\n",
    "    os.makedirs(\n",
    "        os.path.join(path_to_ontology_dir + \"/concept_relationship/\"),\n",
    "        exist_ok=True,\n",
    "    )\n",
    "\n",
    "    concept_map = {}\n",
    "\n",
    "    with io.TextIOWrapper(\n",
    "        zstandard.ZstdCompressor(1).stream_writer(\n",
    "            open(path_to_concept_file, \"wb\")\n",
    "        )\n",
    "    ) as o:\n",
    "        writer = csv.DictWriter(\n",
    "            o,\n",
    "            fieldnames=[ \n",
    "                        \"concept_id\", \"concept_name\", \"domain_id\", \"vocabulary_id\", \n",
    "                        \"concept_class_id\", \"standard_concept\", \"concept_code\", \n",
    "                        \"valid_start_DATE\", \"valid_end_DATE\", \"invalid_reason\", \n",
    "                        \"load_table_id\", \"load_row_id\",\n",
    "            ],\n",
    "        )\n",
    "        writer.writeheader()\n",
    "\n",
    "        next_code: int = 0\n",
    "        for i, c in enumerate(concepts):\n",
    "            code: int = i + next_code\n",
    "            concept_map[c] = code\n",
    "            writer.writerow(\n",
    "                {\n",
    "                    \"concept_id\": str(code), \"concept_name\": c, \"domain_id\": \"Observation\", \n",
    "                    \"vocabulary_id\": \"dummy\", \"concept_class_id\": \"Observation\", \"standard_concept\": \"\", \n",
    "                    \"concept_code\": c, \"valid_start_DATE\": \"1970-01-01\", \"valid_end_DATE\": \"2099-12-31\", \n",
    "                    \"invalid_reason\": \"\", \"load_table_id\": \"custom_mapping\", \"load_row_id\": \"\",\n",
    "                }\n",
    "            )\n",
    "    return concept_map\n",
    "\n",
    "# Create fake ontology\n",
    "path_to_ontology = os.path.join(target_directory, \"ontology\")\n",
    "concepts = set()\n",
    "with transformed_patients.reader() as reader:\n",
    "    for patient in reader:\n",
    "        for e in patient.events:\n",
    "            concepts.add(e.code)\n",
    "concepts = sorted(list(concepts))\n",
    "concept_map = create_ontology(path_to_ontology, concepts)\n",
    "\n",
    "# Remap codes per our fake ontology\n",
    "def transform_event_codes_using_ontology(input: femr.Patient, concept_map: dict) -> femr.Patient:\n",
    "    for e in input.events:\n",
    "        e.code = concept_map[e.code]\n",
    "    return input\n",
    "\n",
    "transformed_patients2 = transformed_patients.transform(\n",
    "    os.path.join(target_directory, \"transformed_patients2\"),\n",
    "    functools.partial(transform_event_codes_using_ontology, concept_map = concept_map),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've created our `Ontology`, we can finally convert our `PatientCollection` to a `PatientDatabase` using the `PatientCollection.to_patient_database()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not find the following concept_id in any of the concept tables2Done with main 2023-05-10T16:11:53.452366748+00:00\n",
      "Done with meta 2023-05-10T16:11:53.452472156+00:00\n"
     ]
    }
   ],
   "source": [
    "# Create patient database\n",
    "transformed_patients2.to_patient_database(\n",
    "    os.path.join(target_directory, 'patient_database'),\n",
    "    path_to_ontology, # Pass the path to the ontology directory we previously created\n",
    "    num_threads=1,\n",
    ").close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "5381b9feecc5c483a184cec838fb477b45f42c56cf211446745f1ac91a2d5966"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
